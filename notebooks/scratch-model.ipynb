{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b><u> Multilayer Perceptron for MNIST Dataset From Scratch</u></b></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Importing Libraries, Classes, and Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Loading the Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(filename):\n",
    "    '''Many file formats use magic numbers so that file readers can easily identify them to verify its reading correct file type. This prevents some errors. Each\n",
    "    pixel is represented from value 0-255 (an unsigned byte/8 bit integer). Metadata is big endian (>, normal) and 4 byte/32 bit integer and stored as 1D array.\n",
    "    file.read(x) takes x bytes from the file and creates an immutable buffer (a bytes object, an array of bytes) and stores it in memory. frombuffer interprets buffer object as array\n",
    "    of bytes of certain data type. It doesn't copy the data just provides a view of the existing data and converts to numpy array.'''\n",
    "    with open(filename, 'rb') as f: #read binary\n",
    "        buffer = f.read(16) #metadata\n",
    "        magic, num_images, rows, cols = np.frombuffer(buffer, dtype='>i4') #rows and columns per image (dimensions)\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8) #read and store remaining data in 1D numpy array; #numpy spaces out elements instead of commas\n",
    "        data = data.reshape(num_images, rows, cols) #reshape flat data into 3D, num_image amt of rows x cols arrays\n",
    "    return data\n",
    "\n",
    "def extract_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_labels = np.frombuffer(f.read(8), dtype='>i4')\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def load_mnist():\n",
    "    data_path = '../data/MNIST/raw'\n",
    "    train_images = extract_images(f'{data_path}/train-images-idx3-ubyte')\n",
    "    train_labels = extract_labels(f'{data_path}/train-labels-idx1-ubyte')\n",
    "    test_images = extract_images(f'{data_path}/t10k-images-idx3-ubyte')\n",
    "    test_labels = extract_labels(f'{data_path}/t10k-labels-idx1-ubyte')\n",
    "    return (train_images, train_labels), (test_images, test_labels) #each dataset is tuple of numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Comma means tuple containing 1 element otherwise would just be int; numpy arrays come with useful attributes like shape\n",
    "(train_images, train_labels), (test_images, test_labels) = load_mnist()\n",
    "\n",
    "print(f\"Train images shape: {train_images.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Creating the Datasets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(images, labels):\n",
    "    dataset = []\n",
    "    for image, label in zip(images, labels): #zip returns iterator of tuples; iterates through both lists at same time\n",
    "        dataset.append((image, label))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_images,  train_labels)\n",
    "test_dataset = create_dataset(test_images,  test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
